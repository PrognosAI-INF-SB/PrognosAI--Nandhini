{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMDkdGSGDePHwhX9SoTDbSl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tboMcYGtH1wA","executionInfo":{"status":"ok","timestamp":1759211007162,"user_tz":-330,"elapsed":51,"user":{"displayName":"NANDHINI PRABAKARAN (RA2311003012101)","userId":"04513527218954099099"}},"outputId":"2d5c8e2e-e46a-411f-8648-79a75af036de"},"outputs":[{"output_type":"stream","name":"stdout","text":["Processed data shape: (1440, 5)\n","Sequences shape: (1411, 30, 3)\n","Sample RUL values: 0    1439\n","1    1438\n","2    1437\n","3    1436\n","4    1435\n","Name: RUL, dtype: int64\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","\n","# Step 1: Load and preprocess the dataset\n","\n","def load_and_preprocess(filepath):\n","    df = pd.read_csv(filepath)\n","\n","    # The dataset columns: ['time', 'SensorA', 'SensorB', 'SensorC']\n","    # Step 1a: Handle missing values only in sensor columns\n","    sensor_cols = ['SensorA', 'SensorB', 'SensorC']\n","    df[sensor_cols] = df[sensor_cols].interpolate(method='linear', limit_direction='both')\n","\n","    # Assert no missing values remain in sensor columns\n","    assert df[sensor_cols].isnull().sum().sum() == 0, \"Missing values remain after interpolation\"\n","\n","    # Step 1b: Standardize sensor data\n","    scaler = StandardScaler()\n","    df[sensor_cols] = scaler.fit_transform(df[sensor_cols])\n","\n","    # Step 1c: Data integrity - no duplicates expected in time series\n","    assert df.duplicated().sum() == 0, \"Duplicate rows found in dataset\"\n","\n","    return df, scaler\n","\n","# Step 2: Create rolling window sequences\n","\n","def create_rolling_windows(df, window_size=30):\n","    sensor_cols = ['SensorA', 'SensorB', 'SensorC']\n","    data = df[sensor_cols].values\n","\n","    sequences = []\n","    for i in range(len(df) - window_size + 1):\n","        seq = data[i:i+window_size]\n","        sequences.append(seq)\n","\n","    return np.array(sequences)\n","\n","# Step 3: Compute Remaining Useful Life (RUL)\n","# Since no engine_id or cycle, assume one continuous time series and RUL decreases to zero\n","\n","def compute_RUL(df):\n","    length = len(df)\n","\n","    # RUL: Remaining cycles till end of data (0 at last time point)\n","    df['RUL'] = np.arange(length-1, -1, -1)\n","    return df\n","\n","# Main execution\n","\n","if __name__ == \"__main__\":\n","    filepath = 'sensor_data.csv'  # Adjust if necessary\n","\n","    # Load and preprocess data\n","    df, scaler = load_and_preprocess(filepath)\n","\n","    # Compute RUL\n","    df = compute_RUL(df)\n","\n","    # Generate rolling window sequences\n","    window_size = 30\n","    sequences = create_rolling_windows(df, window_size)\n","\n","    # Confirm no missing data\n","    assert df.isnull().sum().sum() == 0, \"Missing data present after processing\"\n","\n","    # Display output info\n","    print(\"Processed data shape:\", df.shape)\n","    print(\"Sequences shape:\", sequences.shape)\n","    print(\"Sample RUL values:\", df['RUL'].head())\n"]}]}